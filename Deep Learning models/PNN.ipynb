{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from tqdm import tqdm \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductLayer(nn.Module):\n",
    "    def __init__(self, num_fields, embed_dim, l1_hidden_dim,mode='inner'):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.num_fields = num_fields\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        if mode == 'outer':\n",
    "            # 外积模式需要参数矩阵降维\n",
    "            self.weight = nn.Parameter(torch.randn(embed_dim, embed_dim))\n",
    "        \n",
    "        # 线性部分权重 (保留原始Embedding)\n",
    "        self.linear_weights = nn.Linear(num_fields * embed_dim, num_fields * embed_dim)\n",
    "\n",
    "        self.lz_fc = nn.Linear(num_fields * embed_dim, l1_hidden_dim)\n",
    "        self.lp_fc = nn.Linear(num_fields * (num_fields-1) // 2, l1_hidden_dim)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        \"\"\"\n",
    "        Input: \n",
    "            embeddings: List of tensors [B, embed_dim] * num_fields\n",
    "        Output:\n",
    "            product_output: Tensor [B, output_dim]\n",
    "        \"\"\"\n",
    "        batch_size = embeddings[0].size(0)\n",
    "        stacked = torch.stack(embeddings, dim=1)  # [B, num_fields, embed_dim]\n",
    "        \n",
    "        # 线性部分\n",
    "        linear_part = stacked.view(batch_size, -1)  # [B, num_fields*embed_dim]\n",
    "        linear_out = self.linear_weights(linear_part)\n",
    "        \n",
    "        # 交互部分\n",
    "        if self.mode == 'inner':\n",
    "            # 内积模式：所有向量两两点积\n",
    "            inner_products = []\n",
    "            for i in range(self.num_fields):\n",
    "                for j in range(i+1, self.num_fields):\n",
    "                    ip = torch.sum(embeddings[i] * embeddings[j], dim=1, keepdim=True)\n",
    "                    inner_products.append(ip)\n",
    "            product_out = torch.cat(inner_products, dim=1)  # [B, C(num_fields,2)]\n",
    "            \n",
    "        elif self.mode == 'outer':\n",
    "            # 外积模式：外积矩阵压缩\n",
    "            outer_products = []\n",
    "            for i in range(self.num_fields):\n",
    "                for j in range(i+1, self.num_fields):\n",
    "                    op = torch.bmm(embeddings[i].unsqueeze(2),  # [B, embed_dim, 1]\n",
    "                                 embeddings[j].unsqueeze(1))    # [B, 1, embed_dim]\n",
    "                    \n",
    "                    #op:# [B, embed_dim, embed_dim], self.weight # [embed_dim, embed_dim]\n",
    "                    op = (op * self.weight).sum(dim = (1,2), keepdim = True).squeeze(1)  # 降维,将对位运算的结果相加,并且保持维度为[B,1]\n",
    "                    outer_products.append(op)\n",
    "            product_out = torch.cat(outer_products, dim=1)\n",
    "        \n",
    "        # 合并线性与交互部分\n",
    "        lz_out = self.lz_fc(linear_out)\n",
    "        lp_out = self.lp_fc(product_out)\n",
    "        combined = lz_out + lp_out\n",
    "        combined += self.bias\n",
    "        return torch.relu(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNN(nn.Module):\n",
    "    def __init__(self,fields_feature, embed_dim, hidden_dims, mode = 'inner'):\n",
    "        \"\"\"\n",
    "        fields_feature: list, 每个特征域的类别数目\n",
    "        embed_dim: 嵌入的维度\n",
    "        hidden_dims: list, 隐藏层维度\n",
    "        mode: 计算方式\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #Embedding层\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(input_dim, embed_dim) for input_dim in fields_feature\n",
    "        ])\n",
    "\n",
    "        # 乘积层\n",
    "        self.product_layers = ProductLayer(len(fields_feature), embed_dim, hidden_dims[0],mode)\n",
    "\n",
    "        # 全连接层\n",
    "        product_dim = hidden_dims[0]\n",
    "\n",
    "        fc_layer = []\n",
    "        for hidden_dim in hidden_dims:\n",
    "            fc_layer.append(nn.Linear(product_dim, hidden_dim))\n",
    "            fc_layer.append(nn.ReLU())\n",
    "            product_dim = hidden_dim\n",
    "        self.fc = nn.Sequential(*fc_layer)\n",
    "\n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 1)\n",
    "\n",
    "    def forward(self,field):\n",
    "        embeds = [self.embeddings[i](field[:, i]) for i in range(len(field[0]))]\n",
    "        product_output = self.product_layers(embeds)\n",
    "        fc_output = self.fc(product_output)\n",
    "        output = self.output_layer(fc_output)\n",
    "        return torch.sigmoid(output)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练数据\n",
    "class CTRDataset(Dataset):\n",
    "    def __init__(self, num_samples, fields_feature):\n",
    "        self.num_fields = len(fields_feature)\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 随机生成样本数据\n",
    "        for _ in range(num_samples):\n",
    "            features = [\n",
    "                torch.randint(0, feat_size, (1,)).item()\n",
    "                for feat_size in fields_feature\n",
    "            ]\n",
    "            self.data.append(features)\n",
    "            # 随机生成伪标签（实际使用时替换为真实标签）\n",
    "            label = 1 if features[0] > fields_feature[0]//2 else 0\n",
    "            self.labels.append(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.data[idx], dtype=torch.long),\n",
    "            torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNN(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(15, 16)\n",
      "    (1): Embedding(20, 16)\n",
      "    (2): Embedding(10, 16)\n",
      "    (3): Embedding(12, 16)\n",
      "    (4): Embedding(18, 16)\n",
      "  )\n",
      "  (product_layers): ProductLayer(\n",
      "    (linear_weights): Linear(in_features=80, out_features=80, bias=True)\n",
      "    (lz_fc): Linear(in_features=80, out_features=64, bias=True)\n",
      "    (lp_fc): Linear(in_features=10, out_features=64, bias=True)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 配置训练参数\n",
    "num_samples = 1000  # 样本数量\n",
    "num_fields = 5      # 特征域数量\n",
    "embed_dim = 16\n",
    "fields_feature = [15, 20, 10, 12, 18]  # 每个特征域的类别数目\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "dataset = CTRDataset(num_samples, fields_feature)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 初始化模型实例\n",
    "model = PNN(\n",
    "    fields_feature=fields_feature,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_dims=[64, 32],\n",
    "    mode='inner'\n",
    ").to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()  # 二分类任务\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|██████████| 10/10 [00:00<00:00, 22.26it/s, acc=1, loss=0.000227]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(num_epochs))\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch_idx, (features, labels) in enumerate(dataloader):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device).view(-1, 1)  # 调整标签维度\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播与优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 记录统计信息\n",
    "        total_loss += loss.item()\n",
    "        preds = (outputs > 0.95).float()  # 预测结果阈值为0.95\n",
    "        all_preds.extend(preds.cpu().detach().numpy())\n",
    "        all_labels.extend(labels.cpu().detach().numpy())\n",
    "    \n",
    "    # 计算epoch指标\n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # 打印训练进度\n",
    "    pbar.set_postfix(loss=epoch_loss, acc=epoch_acc)\n",
    "    pbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
