{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossLayer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrossLayer, self).__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim,1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        # 初始化权重\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x0, x_l):\n",
    "        \"\"\"\n",
    "        x0: 初始输入张量，形状(batch_size, input_dim)\n",
    "        x_l: 当前层输入张量，形状(batch_size, input_dim)\n",
    "        返回：x_{l+1} = x0 * x_l^T * W_l + b_l + x_l\n",
    "        \"\"\"\n",
    "        x0 = x0.unsqueeze(2) # (batch_size, input_dim, 1)\n",
    "        x_l_t = x_l.unsqueeze(1) # (batch_size, 1, input_dim)\n",
    "        res = torch.bmm(x0, x_l_t) # (batch_size, input_dim, input_dim)\n",
    "        res = torch.matmul(res, self.weight) # (batch_size, input_dim, 1)\n",
    "        res = res.squeeze(2) # (batch_size, input_dim)\n",
    "        res = res + self.bias + x_l\n",
    "        return res\n",
    "\n",
    "class CrossNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: 输入特征维度\n",
    "            num_layers: 堆叠的CrossLayer层数\n",
    "        \"\"\"\n",
    "        super(CrossNetwork, self).__init__()\n",
    "        self.cross_layers = nn.ModuleList([\n",
    "            CrossLayer(input_dim) for _ in range(num_layers)\n",
    "        ]) \n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 输入张量，形状(batch_size, input_dim)\n",
    "        \"\"\"\n",
    "        x_l = x\n",
    "        for layer in self.cross_layers:\n",
    "            x_l = layer(x,x_l)\n",
    "\n",
    "        return x_l\n",
    "\n",
    "\n",
    "class DeepCrossNetwork(nn.Module):\n",
    "    def __init__(self, num_deep_dim, cat_deep_dims, embedding_dim = 8,cross_num_layers=3, hidden_units = [128, 64],dropout = 0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_deep_dim: Deep部分的数值型特征数量\n",
    "            cat_deep_dims: Deep部分的类别特征维度列表\n",
    "            embedding_dim: 嵌入维度\n",
    "            cross_num_layers: Cross网络的层数\n",
    "            hidden_units: 深度网络隐藏层维度列表\n",
    "        \"\"\"\n",
    "        super(DeepCrossNetwork, self).__init__()\n",
    "\n",
    "        self.num_categorical = len(cat_deep_dims)\n",
    "        self.num_continuous = num_deep_dim\n",
    "        \n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(dim, embedding_dim)\n",
    "            for dim in cat_deep_dims\n",
    "        ])\n",
    "\n",
    "        input_dim = num_deep_dim + len(cat_deep_dims) * embedding_dim\n",
    "\n",
    "        #Cross网络部分\n",
    "        self.cross = CrossNetwork(input_dim, cross_num_layers )\n",
    "\n",
    "        #Deep部分\n",
    "        dnn = []\n",
    "        deep_input_dim = input_dim\n",
    "        for hidden_dim in hidden_units:\n",
    "            dnn.append(nn.Linear(deep_input_dim, hidden_dim))\n",
    "            dnn.append(nn.BatchNorm1d(hidden_dim))\n",
    "            dnn.append(nn.ReLU())\n",
    "            dnn.append(nn.Dropout(dropout))\n",
    "            deep_input_dim = hidden_dim\n",
    "        self.dnn = nn.Sequential(*dnn)\n",
    "\n",
    "        # 最终输出层\n",
    "        self.combined_dim = input_dim + hidden_units[-1]\n",
    "        self.final_layer = nn.Linear(self.combined_dim, 1)\n",
    "\n",
    "    def forward(self, categorical_input, continuous_input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            categorical_input: 类别型输入，形状(batch_size, num_categorical_features)\n",
    "            continuous_input: 数值型输入，形状(batch_size, num_continuous_features)\n",
    "        \"\"\"\n",
    "        # 类别特征嵌入处理\n",
    "        embedded = []\n",
    "        for i in range(self.num_categorical):\n",
    "            emd = self.embeddings[i](categorical_input[:, i])\n",
    "            embedded.append(emd)\n",
    "\n",
    "        embeded = torch.cat(embedded, dim=1) # 形状(batch_size, num_categorical_features * embedding_dim)\n",
    "        \n",
    "        # 拼接数值型特征和嵌入特征\n",
    "        x0 = torch.cat([continuous_input, embeded], dim=1)\n",
    "\n",
    "        # 交叉网络和深度网络\n",
    "        cross_output = self.cross(x0)\n",
    "        deep_output = self.dnn(x0)\n",
    "        # 合并输出\n",
    "        combined_input = torch.cat([cross_output, deep_output], dim=1)\n",
    "\n",
    "        #最终输出\n",
    "        output = self.final_layer(combined_input)\n",
    "        return torch.sigmoid(output).squeeze(1) # 形状(batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义配置\n",
    "config = {\n",
    "    \"cat_deep_dim\": [4, 5, 4],  # 3个类别特征，每个特征的类别数量\n",
    "    \"num_deep_dim\": 8,              # 数值型特征的数量\n",
    "    \"embedding_dim\": 16,               # 嵌入维度\n",
    "    \"cross_num_layers\": 4,            # Cross网络的层数\n",
    "    \"hidden_units\": [128, 64,32],        # 深度网络隐藏层维度列表\n",
    "    \"dropout\": 0.3,                   # Dropout率\n",
    "    \"batch_size\": 32,                 # 批量大小\n",
    "    \"num_epochs\": 30,                 # 训练轮数\n",
    "    \"num_samples\": 1000,              # 数据集样本数量\n",
    "    \"learning_rate\": 0.005            # 学习率\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, num_samples, config):\n",
    "        X, y = make_classification(\n",
    "            n_samples=num_samples,\n",
    "            n_features=config[\"num_deep_dim\"],\n",
    "            n_informative=config[\"num_deep_dim\"] - 2,\n",
    "            n_redundant=2,\n",
    "            n_classes=2,\n",
    "        )\n",
    "        # 随机选取部分数值型特征\n",
    "        self.num_data = torch.tensor(X, dtype=torch.float32)\n",
    "        # 随机生成分类特征\n",
    "        self.deep_data = torch.cat([\n",
    "            torch.randint(0, dim, (num_samples, 1)) for dim in config[\"cat_deep_dim\"]\n",
    "        ], dim=1)\n",
    "\n",
    "        self.labels = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.num_data[idx], self.deep_data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for continuous, categorical, labels in train_loader:\n",
    "        continuous, categorical, labels = continuous.to(device), categorical.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(categorical, continuous)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * continuous.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "# 定义验证函数\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for continuous, categorical, labels in val_loader:\n",
    "            continuous, categorical, labels = continuous.to(device), categorical.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(categorical, continuous)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * continuous.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.93it/s, Train Loss=0.1578, Val Loss=0.4912]\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以确保结果可复现\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 生成数据\n",
    "train_dataset = Dataset(config[\"num_samples\"], config)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(0.7 * len(train_dataset))\n",
    "test_size = len(train_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepCrossNetwork(\n",
    "    num_deep_dim=config[\"num_deep_dim\"],\n",
    "    cat_deep_dims=config[\"cat_deep_dim\"],\n",
    "    embedding_dim=config[\"embedding_dim\"],\n",
    "    cross_num_layers = config[\"cross_num_layers\"],\n",
    "    hidden_units=config[\"hidden_units\"],\n",
    "    dropout = config[\"dropout\"]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"],weight_decay = 1e-3 )\n",
    "\n",
    "# 训练模型\n",
    "pbar = tqdm(range(config[\"num_epochs\"]))\n",
    "for epoch in pbar:\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = validate(model, test_loader, criterion, device)\n",
    "    pbar.set_postfix({'Train Loss': f'{train_loss:.4f}', 'Val Loss': f'{val_loss:.4f}'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
