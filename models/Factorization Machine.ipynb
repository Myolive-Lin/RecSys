{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_processing.data_generate import generate_random_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.FM模型预测公式\n",
    "\n",
    "FM的预测公式包含线性部分和二阶交互部分：\n",
    "\n",
    "$$\n",
    "\\hat{y}(x) = w_0 + \\sum_{i=1}^{n} w_i x_i + \\sum_{i=1}^{n} \\sum_{j=i+1}^{n} (v_i \\cdot v_j) x_i x_j\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $ w_0 $：全局偏置项\n",
    "- $ w_i $：第 $ i $ 个特征的线性权重\n",
    "- $ v_i $：第 $ i $ 个特征的隐向量\n",
    "- $ x_i $：第 $ i $ 个特征的输入值\n",
    "- $ v_i \\cdot v_j $：第 $ i $ 和第 $ j $ 特征的隐向量内积\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**对于上部分进行优化 由$O(kn^2) 到 O(kn)$**\n",
    "其实观察可以发现,原本隐向量部分只有是部分上三角,可以转化成矩阵的全部元素之和一半再减去矩阵的对角线元臺之和的一半：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sum_{i=1}^{n} \\sum_{j=i+1}^{n} (v_i \\cdot v_j) x_i x_j &= \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n} (v_i \\cdot v_j) x_i x_j - \\frac{1}{2} \\sum_{i=1}^{n} (v_i^2) x_i^2\\\\\n",
    "&= \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n}\\sum_{i=1}^{k} (v_{i,f} \\cdot v_{j,f}) x_i x_j - \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{i=1}^{k}(v_{i,f}^2) x_i^2\\\\\n",
    "&= \\frac{1}{2} \\sum_{i=1}^{k} \\left( \\sum_{i=1}^{n} \\sum_{j=1}^{n} (v_{if} \\cdot v_{jf}) x_i x_j - \\sum_{i=1}^{n} (v_{if})^2 x_i^2 \\right)\\\\\n",
    "&= \\frac{1}{2} \\sum_{i=1}^{k} \\left( \\left( \\sum_{i=1}^{n} v_{if} x_i \\right) \\left( \\sum_{j=1}^{n} v_{jf} x_j \\right) - \\sum_{i=1}^{n} (v_{if})^2 x_i^2 \\right)\\\\\n",
    "\n",
    "&= \\frac{1}{2} \\sum_{i=1}^{k} \\left( \\left( \\sum_{i=1}^{n} v_{if} x_i \\right)^2  - \\sum_{i=1}^{n} (v_{if})^2 x_i^2 \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "**优化后预测函数**\n",
    "$$\n",
    "\\hat{y}(x) = w_0 + \\sum_{i=1}^{n} w_i x_i + \\frac{1}{2} \\sum_{i=1}^{k} ( \\sum_{i=1}^{n} v_{if} x_i )^2  - \\sum_{i=1}^{n} (v_{if})^2 x_i^2)\n",
    "$$\n",
    "\n",
    "\n",
    "### 损失函数\n",
    "\n",
    "FM模型的损失函数通常是均方误差（MSE）损失函数，表示为：\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\frac{1}{2} \\sum_{t=1}^{T} (y_t - \\hat{y_t})^2\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $T$ 是训练样本的数量\n",
    "- $y_t$ 是第 $t$ 个样本的真实值\n",
    "- $\\hat{y_t}$ 是第 $t$ 个样本的预测值\n",
    "- $\\theta$ 是模型的所有参数（包括线性权重和隐向量）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 FM模型的梯度公式\n",
    "\n",
    "对于FM模型的参数（包括线性权重 $w$ 和隐向量 $v$），我们需要计算损失函数的梯度，以便使用梯度下降法进行优化。我们可以根据损失函数来推导出每个参数的梯度。\n",
    "\n",
    "#### 偏置项 $w_0$ 梯度：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_0} = \\hat{y_t} - y_t\n",
    "$$\n",
    "\n",
    "#### 线性权重 $w_i$ 梯度：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_i} = (\\hat{y_t} - y_t) \\cdot x_i\n",
    "$$\n",
    "\n",
    "#### 隐向量 $v_i$ 梯度：\n",
    "\n",
    "隐向量的梯度较为复杂，推导过程如下：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial v_i} = (\\hat{y_t} - y_t) \\cdot \\left( \\sum_{j=1}^{n} v_j x_j - v_i x_i \\right) \\cdot x_i\\\\\n",
    "= (\\hat{y_t} - y_t) \\cdot \\left( x_i \\sum_{j=1}^{n} v_j x_j - v_i x_i^2\\right)  \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine:\n",
    "    def __init__(self, n_features, k, learning_rate=0.01, n_iter=1000):\n",
    "        \"\"\"\n",
    "        初始化因子分解机模型。\n",
    "        参数：\n",
    "        - n_features: 特征数量\n",
    "        - k: 隐向量的维度\n",
    "        - learning_rate: 学习率\n",
    "        - n_iter: 迭代次数\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        # 初始化参数\n",
    "        self.w0 = 0\n",
    "        self.w = np.zeros(n_features) # 线性权重\n",
    "        self.V = np.random.normal(scale = 1.0 / k, size = (n_features, k))# 隐向量矩阵\n",
    "\n",
    "\n",
    "    def _predict_instance(self, x):\n",
    "        \"\"\"\n",
    "        预测单个样本的输出。\n",
    "        参数：\n",
    "        - x: 输入特征向量\n",
    "        返回：\n",
    "        - 预测值\n",
    "        \"\"\"\n",
    "        linear_terms = self.w0 + np.dot(self.w, x)\n",
    "        interactions = 0.5 * np.sum(\n",
    "            np.square(np.dot(x, self.V)) - np.dot(x ** 2, self.V ** 2)\n",
    "        )\n",
    "        return linear_terms + interactions\n",
    "         \n",
    "\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "        训练因子分解机模型。\n",
    "        参数：\n",
    "        - X: 特征矩阵，形状为(n_samples, n_features)\n",
    "        - y: 目标向量，形状为(n_samples,)\n",
    "        \"\"\"\n",
    "\n",
    "        pbar = tqdm(range(self.n_iter), desc = \"Training FM\", ncols = 100, unit = \"iter\")\n",
    "        for _ in pbar:\n",
    "            rows, cols = X.shape\n",
    "            mse = 0\n",
    "            for i in range(rows):\n",
    "                prediction = self._predict_instance(X[i])\n",
    "                yi = y[i]\n",
    "                error = (prediction - yi).astype(np.float32)\n",
    "                mse += error ** 2\n",
    "                \n",
    "\n",
    "                #更新参数\n",
    "                self.w0 -= self.learning_rate * error\n",
    "                self.w -= self.learning_rate * error *X[i]\n",
    "\n",
    "                # 计算 V 的更新，使用矩阵运算来代替逐元素的运算\n",
    "                x_square = X[i] ** 2  # (n_features,)\n",
    "                x_V = np.dot(X[i], self.V)  # (1,k)\n",
    "                grad_V = error * (\n",
    "                    #这纬度一致其实是矩阵乘法\n",
    "                    np.dot(X[i].reshape(-1, 1), x_V.reshape(1, -1)) #(n_features,k)\n",
    "                    - self.V * x_square.reshape(-1, 1) #(n_features,k) 广播机制\n",
    "                )\n",
    "                self.V -= self.learning_rate * grad_V\n",
    "            pbar.set_postfix({\"MSE\": mse})\n",
    "\n",
    "            \n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        预测样本的输出。\n",
    "        参数：\n",
    "        - X: 特征矩阵，形状为(n_samples, n_features)\n",
    "        返回：\n",
    "        - 预测值数组，形状为(n_samples,)\n",
    "        \"\"\"\n",
    "        return np.array([self._predict_instance(xi) for xi in X])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验模拟\n",
    "注意由于没有合适的数据集，所以这里我们使用随机生成的数据来模拟实验,并且因为生成的数据不一定存在规律,所以只用生成的数据进行预测,而没有使用测试集来评估模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建矩阵\n",
    "rows,cols = 100,8\n",
    "matrix = generate_random_matrix(rows = rows,cols = cols,min_value = 0, max_value = 5,seed = 42)\n",
    "np.random.seed(42)\n",
    "y = np.random.rand(rows,1)\n",
    "res = pd.DataFrame(np.concatenate((matrix,y),axis = 1),index = range(1,rows + 1),columns = list(range(1,cols + 1)) + ['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM = FactorizationMachine(n_features = cols,k = 5, learning_rate = 0.001,n_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training FM: 100%|███████████████████████████| 1000/1000 [00:03<00:00, 280.45iter/s, MSE=[7.250213]]\n"
     ]
    }
   ],
   "source": [
    "FM.fit(matrix,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.605124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.527338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.815019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.584716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.523286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.493796</td>\n",
       "      <td>0.555199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522733</td>\n",
       "      <td>0.420619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.427541</td>\n",
       "      <td>0.478358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.125237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.107891</td>\n",
       "      <td>0.178776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8         y    y_pred\n",
       "1    3.0  4.0  2.0  4.0  4.0  1.0  2.0  2.0  0.374540  0.605124\n",
       "2    2.0  4.0  3.0  2.0  5.0  4.0  1.0  3.0  0.950714  0.527338\n",
       "3    5.0  5.0  1.0  3.0  4.0  0.0  3.0  1.0  0.731994  0.815019\n",
       "4    5.0  4.0  3.0  0.0  0.0  2.0  2.0  1.0  0.598658  0.584716\n",
       "5    3.0  3.0  5.0  5.0  5.0  2.0  3.0  3.0  0.156019  0.523286\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...       ...       ...\n",
       "96   5.0  1.0  2.0  4.0  0.0  1.0  1.0  5.0  0.493796  0.555199\n",
       "97   1.0  2.0  4.0  4.0  0.0  5.0  0.0  1.0  0.522733  0.420619\n",
       "98   0.0  2.0  4.0  1.0  0.0  5.0  2.0  2.0  0.427541  0.478358\n",
       "99   0.0  4.0  0.0  1.0  0.0  2.0  0.0  4.0  0.025419  0.125237\n",
       "100  5.0  3.0  0.0  4.0  4.0  5.0  2.0  4.0  0.107891  0.178776\n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['y_pred'] = FM.predict(matrix)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### pytroch实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(torch.nn.Module):\n",
    "    def __init__(self,n_features, k):\n",
    "        \"\"\"\n",
    "        初始化因子分解机模型。\n",
    "        参数：\n",
    "        - n_features: 特征数量\n",
    "        - k: 隐向量的维度\n",
    "        \"\"\"\n",
    "\n",
    "        super(FM,self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.k = k\n",
    "\n",
    "        #初始化模型参数\n",
    "        self.w0 = nn.Parameter(torch.zeros(1))\n",
    "        self.w = nn.Parameter(torch.zeros(n_features))\n",
    "        self.V = nn.Parameter(torch.zeros(n_features,k) * 0.01)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        定义前向传播。\n",
    "        参数：\n",
    "        - X: 输入特征矩阵，形状为 (batch_size, n_features)\n",
    "        返回：\n",
    "        - 预测值 (batch_size,)\n",
    "        \"\"\"\n",
    "\n",
    "        #线性部分\n",
    "        linear_terms = self.w0 + torch.matmul(X, self.w)\n",
    "\n",
    "        # 二阶交互部分 (优化计算)\n",
    "        interactions = 0.5 * torch.sum(\n",
    "            torch.pow(torch.matmul(X,self.V),2) - - torch.matmul(torch.pow(X, 2), torch.pow(self.V, 2)), dim=1 \n",
    "        )\n",
    "\n",
    "        return linear_terms + interactions\n",
    "\n",
    "\n",
    "def train_fm(model,optimizer, criterion, X, y, n_epochs):\n",
    "    \"\"\"\n",
    "    训练FM模型。\n",
    "    参数：\n",
    "    - model: FM模型实例\n",
    "    - optimizer: 优化器\n",
    "    - criterion: 损失函数\n",
    "    - X: 训练数据 (torch.Tensor)\n",
    "    - y: 目标值 (torch.Tensor)\n",
    "    - n_epochs: 训练轮数\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(range(n_epochs), desc=\"Training FM\", ncols=100, unit=\"epoch\")\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, y)\n",
    "\n",
    "        #反向传播   \n",
    "        optimizer.zero_grad() #清除梯度\n",
    "        loss.backward()       #计算梯度\n",
    "        optimizer.step()      #更新参数\n",
    "        \n",
    "        #显示损失\n",
    "        pbar.set_postfix({'Loss':loss.item()})\n",
    "\n",
    "def predict_fm(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training FM: 100%|████████████████████████████████| 100/100 [00:00<00:00, 643.01epoch/s, Loss=0.984]\n"
     ]
    }
   ],
   "source": [
    "#数据准备\n",
    "n_features = 10\n",
    "k = 5\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "X = torch.randn(100, n_features)\n",
    "y = torch.randn(100)\n",
    "\n",
    "fm_model = FM(n_features = n_features, k = k)\n",
    "criterion = nn.MSELoss() # 使用均方误差损失函数\n",
    "optimizer = optim.Adam(fm_model.parameters(), lr = 0.01)\n",
    "\n",
    "train_fm(fm_model, optimizer = optimizer, criterion = criterion, X=X, y=y, n_epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.9269)</td>\n",
       "      <td>tensor(1.4873)</td>\n",
       "      <td>tensor(0.9007)</td>\n",
       "      <td>tensor(-2.1055)</td>\n",
       "      <td>tensor(0.6784)</td>\n",
       "      <td>tensor(-1.2345)</td>\n",
       "      <td>tensor(-0.0431)</td>\n",
       "      <td>tensor(-1.6047)</td>\n",
       "      <td>tensor(-0.7521)</td>\n",
       "      <td>tensor(1.6487)</td>\n",
       "      <td>0.101067</td>\n",
       "      <td>0.237655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(-0.3925)</td>\n",
       "      <td>tensor(-1.4036)</td>\n",
       "      <td>tensor(-0.7279)</td>\n",
       "      <td>tensor(-0.5594)</td>\n",
       "      <td>tensor(-0.7688)</td>\n",
       "      <td>tensor(0.7624)</td>\n",
       "      <td>tensor(1.6423)</td>\n",
       "      <td>tensor(-0.1596)</td>\n",
       "      <td>tensor(-0.4974)</td>\n",
       "      <td>tensor(0.4396)</td>\n",
       "      <td>-1.309492</td>\n",
       "      <td>-0.170638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(-0.7581)</td>\n",
       "      <td>tensor(1.0783)</td>\n",
       "      <td>tensor(0.8008)</td>\n",
       "      <td>tensor(1.6806)</td>\n",
       "      <td>tensor(1.2791)</td>\n",
       "      <td>tensor(1.2964)</td>\n",
       "      <td>tensor(0.6105)</td>\n",
       "      <td>tensor(1.3347)</td>\n",
       "      <td>tensor(-0.2316)</td>\n",
       "      <td>tensor(0.0418)</td>\n",
       "      <td>-0.410358</td>\n",
       "      <td>0.360829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(-0.2516)</td>\n",
       "      <td>tensor(0.8599)</td>\n",
       "      <td>tensor(-1.3847)</td>\n",
       "      <td>tensor(-0.8712)</td>\n",
       "      <td>tensor(-0.2234)</td>\n",
       "      <td>tensor(1.7174)</td>\n",
       "      <td>tensor(0.3189)</td>\n",
       "      <td>tensor(-0.4245)</td>\n",
       "      <td>tensor(0.3057)</td>\n",
       "      <td>tensor(-0.7746)</td>\n",
       "      <td>0.468094</td>\n",
       "      <td>-0.080337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(-1.5576)</td>\n",
       "      <td>tensor(0.9956)</td>\n",
       "      <td>tensor(-0.8798)</td>\n",
       "      <td>tensor(-0.6011)</td>\n",
       "      <td>tensor(-1.2742)</td>\n",
       "      <td>tensor(2.1228)</td>\n",
       "      <td>tensor(-1.2347)</td>\n",
       "      <td>tensor(-0.4879)</td>\n",
       "      <td>tensor(-0.9138)</td>\n",
       "      <td>tensor(-0.6581)</td>\n",
       "      <td>-0.234628</td>\n",
       "      <td>-0.057512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tensor(0.5692)</td>\n",
       "      <td>tensor(-0.7911)</td>\n",
       "      <td>tensor(-0.1990)</td>\n",
       "      <td>tensor(-1.3616)</td>\n",
       "      <td>tensor(-0.5194)</td>\n",
       "      <td>tensor(0.0765)</td>\n",
       "      <td>tensor(0.3401)</td>\n",
       "      <td>tensor(1.4557)</td>\n",
       "      <td>tensor(-0.3461)</td>\n",
       "      <td>tensor(-0.2634)</td>\n",
       "      <td>-0.014565</td>\n",
       "      <td>-0.286557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tensor(-0.4477)</td>\n",
       "      <td>tensor(-0.7288)</td>\n",
       "      <td>tensor(-0.1607)</td>\n",
       "      <td>tensor(-0.3206)</td>\n",
       "      <td>tensor(-0.6308)</td>\n",
       "      <td>tensor(-0.7888)</td>\n",
       "      <td>tensor(1.3062)</td>\n",
       "      <td>tensor(-0.9276)</td>\n",
       "      <td>tensor(-0.2627)</td>\n",
       "      <td>tensor(0.9315)</td>\n",
       "      <td>-0.748688</td>\n",
       "      <td>-0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tensor(-0.4593)</td>\n",
       "      <td>tensor(-0.9419)</td>\n",
       "      <td>tensor(-0.7089)</td>\n",
       "      <td>tensor(2.1861)</td>\n",
       "      <td>tensor(-0.6493)</td>\n",
       "      <td>tensor(0.4521)</td>\n",
       "      <td>tensor(0.8521)</td>\n",
       "      <td>tensor(-1.6947)</td>\n",
       "      <td>tensor(1.1806)</td>\n",
       "      <td>tensor(-2.8929)</td>\n",
       "      <td>-0.384403</td>\n",
       "      <td>-0.337158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tensor(-0.3876)</td>\n",
       "      <td>tensor(-0.7124)</td>\n",
       "      <td>tensor(-1.6171)</td>\n",
       "      <td>tensor(-0.3590)</td>\n",
       "      <td>tensor(-0.4137)</td>\n",
       "      <td>tensor(-0.5285)</td>\n",
       "      <td>tensor(-0.5082)</td>\n",
       "      <td>tensor(1.1478)</td>\n",
       "      <td>tensor(0.2401)</td>\n",
       "      <td>tensor(-0.7907)</td>\n",
       "      <td>0.143502</td>\n",
       "      <td>-0.181565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tensor(-0.8132)</td>\n",
       "      <td>tensor(0.1415)</td>\n",
       "      <td>tensor(1.5630)</td>\n",
       "      <td>tensor(0.5983)</td>\n",
       "      <td>tensor(-0.5407)</td>\n",
       "      <td>tensor(0.7842)</td>\n",
       "      <td>tensor(0.6991)</td>\n",
       "      <td>tensor(-0.0363)</td>\n",
       "      <td>tensor(-0.3798)</td>\n",
       "      <td>tensor(-0.8535)</td>\n",
       "      <td>-0.081268</td>\n",
       "      <td>-0.101379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                1                2                3  \\\n",
       "0    tensor(1.9269)   tensor(1.4873)   tensor(0.9007)  tensor(-2.1055)   \n",
       "1   tensor(-0.3925)  tensor(-1.4036)  tensor(-0.7279)  tensor(-0.5594)   \n",
       "2   tensor(-0.7581)   tensor(1.0783)   tensor(0.8008)   tensor(1.6806)   \n",
       "3   tensor(-0.2516)   tensor(0.8599)  tensor(-1.3847)  tensor(-0.8712)   \n",
       "4   tensor(-1.5576)   tensor(0.9956)  tensor(-0.8798)  tensor(-0.6011)   \n",
       "..              ...              ...              ...              ...   \n",
       "95   tensor(0.5692)  tensor(-0.7911)  tensor(-0.1990)  tensor(-1.3616)   \n",
       "96  tensor(-0.4477)  tensor(-0.7288)  tensor(-0.1607)  tensor(-0.3206)   \n",
       "97  tensor(-0.4593)  tensor(-0.9419)  tensor(-0.7089)   tensor(2.1861)   \n",
       "98  tensor(-0.3876)  tensor(-0.7124)  tensor(-1.6171)  tensor(-0.3590)   \n",
       "99  tensor(-0.8132)   tensor(0.1415)   tensor(1.5630)   tensor(0.5983)   \n",
       "\n",
       "                  4                5                6                7  \\\n",
       "0    tensor(0.6784)  tensor(-1.2345)  tensor(-0.0431)  tensor(-1.6047)   \n",
       "1   tensor(-0.7688)   tensor(0.7624)   tensor(1.6423)  tensor(-0.1596)   \n",
       "2    tensor(1.2791)   tensor(1.2964)   tensor(0.6105)   tensor(1.3347)   \n",
       "3   tensor(-0.2234)   tensor(1.7174)   tensor(0.3189)  tensor(-0.4245)   \n",
       "4   tensor(-1.2742)   tensor(2.1228)  tensor(-1.2347)  tensor(-0.4879)   \n",
       "..              ...              ...              ...              ...   \n",
       "95  tensor(-0.5194)   tensor(0.0765)   tensor(0.3401)   tensor(1.4557)   \n",
       "96  tensor(-0.6308)  tensor(-0.7888)   tensor(1.3062)  tensor(-0.9276)   \n",
       "97  tensor(-0.6493)   tensor(0.4521)   tensor(0.8521)  tensor(-1.6947)   \n",
       "98  tensor(-0.4137)  tensor(-0.5285)  tensor(-0.5082)   tensor(1.1478)   \n",
       "99  tensor(-0.5407)   tensor(0.7842)   tensor(0.6991)  tensor(-0.0363)   \n",
       "\n",
       "                  8                9         y    y_pred  \n",
       "0   tensor(-0.7521)   tensor(1.6487)  0.101067  0.237655  \n",
       "1   tensor(-0.4974)   tensor(0.4396) -1.309492 -0.170638  \n",
       "2   tensor(-0.2316)   tensor(0.0418) -0.410358  0.360829  \n",
       "3    tensor(0.3057)  tensor(-0.7746)  0.468094 -0.080337  \n",
       "4   tensor(-0.9138)  tensor(-0.6581) -0.234628 -0.057512  \n",
       "..              ...              ...       ...       ...  \n",
       "95  tensor(-0.3461)  tensor(-0.2634) -0.014565 -0.286557  \n",
       "96  tensor(-0.2627)   tensor(0.9315) -0.748688 -0.001467  \n",
       "97   tensor(1.1806)  tensor(-2.8929) -0.384403 -0.337158  \n",
       "98   tensor(0.2401)  tensor(-0.7907)  0.143502 -0.181565  \n",
       "99  tensor(-0.3798)  tensor(-0.8535) -0.081268 -0.101379  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_fm(fm_model,X)\n",
    "\n",
    "res_torch = pd.DataFrame(X)\n",
    "res_torch['y'] = y\n",
    "res_torch['y_pred'] = y_pred\n",
    "\n",
    "res_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
